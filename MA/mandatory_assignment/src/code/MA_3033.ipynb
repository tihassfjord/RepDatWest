{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gradient_checks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradient_checks\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcnn\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mHE_mnist_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_mnist, plot_mnist_results\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gradient_checks'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "sys.path.append('code/')\n",
    "sys.path.append('data/')\n",
    "import gradient_checks\n",
    "import cnn\n",
    "from HE_mnist_loader import load_mnist, plot_mnist_results\n",
    "\n",
    "print(\"******************\\nSTARTING PROBLEM 1\\n******************\")\n",
    "print(\"In order to validate your implementation of the backward pass we run a \\\n",
    "gradient check for the layer implementations. Note, that an relative error of less than 1e-6 \\\n",
    "most likely indicates that the gradient is correct.\")\n",
    "\n",
    "gradient_checks.check_gradient_conv()\n",
    "gradient_checks.check_gradient_pool()\n",
    "gradient_checks.check_gradient_relu()\n",
    "gradient_checks.check_gradient_fc()\n",
    "\n",
    "input(\"If the gradients look ok, press Enter to continue training the model...\")\n",
    "\n",
    "x_tr, y_tr, x_te, y_te = load_mnist(plot=True)\n",
    "\n",
    "BS = 500\n",
    "\n",
    "model = cnn.CNN()\n",
    "model.train(x_tr, y_tr, 100, BS)\n",
    "\n",
    "out = model.test(x_te)\n",
    "pred = np.argmax(out, axis=1)\n",
    "\n",
    "plot_mnist_results(x_te, pred, y_te)\n",
    "print(\"ACC: \", np.sum(pred == y_te)/float(500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gradient_checks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradient_checks\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mHE_tweets_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tweets, vecToWords, load_tweets_concat\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrnn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gradient_checks'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "sys.path.append('code/')\n",
    "sys.path.append('data/')\n",
    "import gradient_checks\n",
    "from HE_tweets_loader import load_tweets, vecToWords, load_tweets_concat\n",
    "import rnn\n",
    "\n",
    "dataset = 'shake'\n",
    "\n",
    "print(\"******************\\nSTARTING PROBLEM 2\\n******************\")\n",
    "print(\"Gradient check for the fully connected layer implementations. Note, that an relative error of less than 1e-6\\\n",
    "most likely indicates that the gradient is correct.\")\n",
    "\n",
    "gradient_checks.check_gradient_fc()\n",
    "gradient_checks.check_gradient_wordembedding()\n",
    "gradient_checks.check_gradient_recurrent_step()\n",
    "gradient_checks.check_gradient_rnn()\n",
    "\n",
    "input(\"If the gradients look ok, press Enter to continue training the model...\")\n",
    "\n",
    "length = 20000\n",
    "if dataset == 'shake':\n",
    "\n",
    "    data = open('data/shake.txt', 'r').read()\n",
    "    chars = list(set(data))\n",
    "    data_size, vocab_size = len(data), len(chars)\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "    np.save('data/map_shake.npy', ix_to_char)\n",
    "\n",
    "    p = 0\n",
    "    seq_length = data_size\n",
    "    \n",
    "    inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "    \n",
    "    xs = np.zeros((vocab_size,data_size),dtype=np.int)\n",
    "    \n",
    "    for t in range(data_size):\n",
    "        xs[inputs[t], t] = np.int(1)\n",
    "\n",
    "    seq_length = 50\n",
    "    model = rnn.RNN(vocab_size=vocab_size)\n",
    "    model.train(np.array(inputs[:length]).reshape(1, length), 5001, 1, seq_length, dataset)\n",
    "\n",
    "if dataset == 'trump':\n",
    "\n",
    "    z = load_tweets_concat()\n",
    "    z = z[z != 44]\n",
    "    z = z[z != 43]\n",
    "    \n",
    "    x = z\n",
    "    x = x[np.newaxis]\n",
    "    seq_length = 50\n",
    "    model = rnn.RNN()\n",
    "    model.train(np.array(x[:, :length]), 6001, 1, seq_length, dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
